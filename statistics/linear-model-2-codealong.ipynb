{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models: Categorical predictors, and Multiple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>diurnal_temp_range</th>\n",
       "      <th>precip-total</th>\n",
       "      <th>snow-totals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00054704</td>\n",
       "      <td>NORWOOD MEMORIAL AIRPORT, MA US</td>\n",
       "      <td>1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>3.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00054704</td>\n",
       "      <td>NORWOOD MEMORIAL AIRPORT, MA US</td>\n",
       "      <td>2</td>\n",
       "      <td>28.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00054704</td>\n",
       "      <td>NORWOOD MEMORIAL AIRPORT, MA US</td>\n",
       "      <td>3</td>\n",
       "      <td>36.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00054704</td>\n",
       "      <td>NORWOOD MEMORIAL AIRPORT, MA US</td>\n",
       "      <td>4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>4.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00054704</td>\n",
       "      <td>NORWOOD MEMORIAL AIRPORT, MA US</td>\n",
       "      <td>5</td>\n",
       "      <td>56.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>3.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station                             name  date  temp  \\\n",
       "0  USW00054704  NORWOOD MEMORIAL AIRPORT, MA US     1  25.9   \n",
       "1  USW00054704  NORWOOD MEMORIAL AIRPORT, MA US     2  28.9   \n",
       "2  USW00054704  NORWOOD MEMORIAL AIRPORT, MA US     3  36.4   \n",
       "3  USW00054704  NORWOOD MEMORIAL AIRPORT, MA US     4  46.8   \n",
       "4  USW00054704  NORWOOD MEMORIAL AIRPORT, MA US     5  56.4   \n",
       "\n",
       "   diurnal_temp_range  precip-total  snow-totals  \n",
       "0                19.7          3.43          NaN  \n",
       "1                21.0          3.25          NaN  \n",
       "2                21.5          4.45          NaN  \n",
       "3                22.7          4.19          NaN  \n",
       "4                24.9          3.68          NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load standard libraries for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# packages for statistics\n",
    "import scipy.stats as stats\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from utils import Linear_Reg_Diagnostic\n",
    "\n",
    "df = pd.read_csv('../data/boston_precip_temp.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review from last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = df.loc[(df['snow-totals']>0) & (df['snow-totals'].notnull()) & (df['temp'].notnull()),:].reset_index(drop=True)\n",
    "df_sub = df_sub.rename(columns={'precip-total':'precip_total','snow-totals':'snow_total'})\n",
    "\n",
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(  )\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting predictions out of model\n",
    "\n",
    "We covered this briefly last time, but we can get the regression coefficients out of our model using `.params`, which gives us back a Pandas Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use integer or string indexing to get the parameters out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually use these to make predictions from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# estimate for a temp of 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models also have a method to make predictions called `.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Work in groups. Using the gapminder dataset, create models predicting life expectancy with different numerical variables. Which columns give the highest R-squared values as predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = pd.read_csv('../data/gapminder.csv')\n",
    "\n",
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "Above, we used one continuous variable $x$ to predict another continuous variable $y$. However, linear regression is flexible: we can also use a categorical x as a predictor. \n",
    "\n",
    "To do this, we essentially convert our categories into numbers. Say we have a categorical variable with only 2 levels. Our penguins data set (loaded below) has a variable “sex” that has the values of “female” and “male”. We can transform the “sex” column to be equal to 0 where before it was “female” and 1 where it was “male”. We now have turned our categorical data into numbers. This is called creating a dummy variable. Statsmodels does this conversion automatically, though you also can encode the categorical variables as numerical variables manually.\n",
    "\n",
    "Our model now can only make two predictions: the value for $y$ when $x$ is 0 and the value when $x$ is 1. $\\beta_0$ is the predicted value when $x$ is 0, and $\\beta_1  + \\beta_0$ is the value $x$ is 1.\n",
    "\n",
    "We can still use the same diagnostic plots for this regression model, but because there are only two possible predicted values, they will look strange. You can use the same rules of thumb for most of them. However, the QQ plot is not worth examining. \n",
    "\n",
    "Assuming you let statsmodels do the conversion for you, when you look at the model summary, most of it will be the same. The main difference in interpretation is that the estimate for the intercept coefficient is the prediction when $x$ = 0, and the estimate for the other coefficient is when x = 1. It should be labeled so that the appropriate level for $x$ = 1 is apparent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = pd.read_csv('../data/penguins.csv')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_model = smf.ols(formula = \"  \",data=penguins).fit()\n",
    "penguins_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_diag = Linear_Reg_Diagnostic(penguins_model)\n",
    "\n",
    "pen_diag.residual_plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_diag.scale_location_plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_diag.leverage_plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_diag.qq_plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your categorical variable has multiple levels (more than 2), we can still turn into dummy variables. For example, if the categorical variable is “side”, and the levels are “left”, “right”, and “center”, you could make two dummy variable columns “left” and “right”. When “side” was “left”, the column “left” will be 1, and the column “right” will be 0. The opposite is true when “side” was “right”. When “side” is “middle”, both the “left” and “right” columns will be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_model2 = smf.ols(formula = \"\",data=penguins).fit()\n",
    "penguins_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple regression\n",
    "We do not need to restrict ourselves to using a single predictor. We can use any combo of numerical or categorical variables. For instance, if you have two predictor variables, the regression equation becomes: \n",
    "\n",
    "$$y = \\beta_0+\\beta_1x_1+\\beta_2x_2$$\n",
    "\n",
    "$x_1$ is one independent variable, or predictor, and $x_2$ is the other. $\\beta_0$ is still the intercept, and it is the predicted value when both $x_1$ and $x_2$ are 0. $\\beta_1$ is still a regression coefficient, and it represents the amount we expect $y$ to change when $x_1$ changes one unit. Similarly, $\\beta_2$ is the amount we expect $y$ to change when $x_2$ changes one unit. \n",
    "\n",
    "We can expand this equation for however many independent variables we want to include:\n",
    "\n",
    "$$y = \\beta_0+\\beta_1x_1+\\beta_2x_2+ . . .+\\beta_nx_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted R-squared\n",
    "When we add new terms to our model, the standard R squared will always go up, no matter whether or not if the new variables are really accounting for variance in y. Adjusted R squared tries to account for this inflation, and may actually lower the R squared if the new variables do not help predict the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = smf.ols(formula='  ',data=penguins).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2 = Linear_Reg_Diagnostic(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2.residual_plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity\n",
    "When we include multiple terms in our regression, some of these variables may be correlated with each other. This is called multicollinearity and can lead to issues when estimating the values of the regression coefficients and their corresponding p-values. \n",
    "\n",
    "To see if there is multicollinearity in your model you can calculate the variance inflation factor for each predictor variable. It lets us know how much larger the variance in the estimation of that predictor is with the other variables included, versus without the other variables. \n",
    "\n",
    "A general guideline is that a VIF above 5 or 10 is rather high. You can try re-running your regression model without predictors with high VIFs, and if the R-squared does not change too much, that is a good modification. However, if the R-squared gets drastically smaller, you might consider removing other variables. \n",
    "\n",
    "In general, we want models to have high predictive power but to also contain relatively few terms. The more terms a model contains, the less interpretable and understandable it is. The fewer variables needed to explain a phenomenon, the better. However, sometimes, the value you are trying to predict has a complicated relationship with your data, and you may need many predictors to explain it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_dummies\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap( )\n",
    "plt.xticks(rotation=45);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple categorical variables\n",
    "model3 = smf.ols(formula=\"\", data=penguins).fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = smf.ols(formula=\"  \", data=penguins).fit()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag4 = Linear_Reg_Diagnostic(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "Work in groups. Make the best model you can to predict bill length from the other variables in the data set. Try to not have any variables with a high VIF, but to also have a high R-squared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52b534d3e8b2df8a7f375ea8b488ed7c2e546a5d77230d70bd2c6badbd8c861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
