{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation and time series modeling\n",
    "## Time series data\n",
    "\n",
    "Repeated samples taken at regular time intervals\n",
    "\n",
    "Allows us to examine trends over time, as well as noise in data\n",
    "\n",
    "When dealing with time series information, a big focus is often to forecast future values. This can be quite difficult, as uncertainty is larger the further out into the future we go. \n",
    "\n",
    "Time series analysis is a very complicated field, and we are just going to scratch the surface of it. You could take a whole class just on time series analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use data from World Bank that has mean annual air temperatures for the last 100+ years.\n",
    "\n",
    "We're going to subset to data starting at 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/usa-annual-temp.csv')\n",
    "df = df.loc[df['year']>=1970,:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, we're going to convert year values to the data type datetime.\n",
    "\n",
    "We will also set our index (row names) to be the year values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = \n",
    "# makes sure years are in order\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this done, we can visualize the time series as a line plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['temp']);\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Temp (C)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature appears to be increasing over time, but it is not constantly increasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation\n",
    "\n",
    "Time series data has an important feature: it is sequential, meaning that we know the values before and after a given data point. \n",
    "\n",
    "Data points that are close together in time are likely to be correlated. This is a good starting point for our analysis. \n",
    "\n",
    "What we can do is calculate the correlation between our data points and the values directly before them. This is called **autocorrelation**: correlating our data with itself.\n",
    "\n",
    "Specifically, we are going to see how much data from a given year is correlated with the data in the following year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    " # how many years removed?\n",
    "\n",
    "# current year\n",
    "\n",
    "# one year prior\n",
    "\n",
    "# calcualte correlation\n",
    "r, p = \n",
    "print('correlation:', r)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot an **autocorrelation function** (ACF) that shows the autocorrelation for various lags. \n",
    "\n",
    "Significant autocorrelation is the points above or below the highlighted blue zone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity: Augmented Dickey-Fuller Test (ADF Test)\n",
    "\n",
    "Before we can model our time series, we need our data to be **stationary**: the mean and variance of the data have to be constant across the time series.\n",
    "\n",
    "Looking at our data, it is pretty safe to conclude it is not stationary -> the mean increases as time passes.\n",
    "\n",
    "However, to concretely test this, we can use the ADF test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the output from this function is pretty overwhelming. Here's a function to make it look a bit more clear.\n",
    "\n",
    "The important part here is the p-value, which represents the probability of observing this time series if the true process is not stationary. \n",
    "\n",
    "Because our p-value is quite large, we have to accept the null hypothesis that our time series is not stationary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_print(time_series):\n",
    "    adf_output = adfuller(time_series)\n",
    "    stat = adf_output[0]\n",
    "    pval = adf_output[1]\n",
    "    print('ADF Statistic:', stat)\n",
    "    print('p-value:', pval)\n",
    "    return None\n",
    "\n",
    "adf_print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression to quantify trend\n",
    "\n",
    "If the time series is not stationary, it likely has a trend. In our case, the trend is linear, so we can use linear regression to quantify the trend.\n",
    "\n",
    "If your data has a trend that is not linear, you can consider transformation, or breaking your time series into pieces that have linear trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df1 = pd.read_csv('../data/usa-annual-temp.csv')\n",
    "df1 = df1.loc[df1['year']>=1970,:]\n",
    "\n",
    "\n",
    "model = ols(formula=\"temp~year\", data=df1).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differencing\n",
    "\n",
    "We need to remove the trend from our data. There are several ways to do this, but one of the most reliable ways is to use **differencing** to transform it. \n",
    "\n",
    "Differencing is simply subtracting each value in the time series by the subsequent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize our time series and see it is now stationary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_diff)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Temp (differenced)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure, we can run the ADF test again, as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_print(y_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now revisit our ACF plot and see how it has changed now.  \n",
    "\n",
    "You can see the only significant lag is now 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(y_diff, lags=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a similar plot called a partial autocorrelation function (PACF). It is similar but has a slightly different interpretation. For more information, please see [this article](https://www.linkedin.com/pulse/time-series-analysis-short-introduction-/?trk=pulse-article).\n",
    "\n",
    "Our PACF has significant lags of 2, 3, and 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the fact that we have significant autocorrelation try to make a model.\n",
    "\n",
    "We're going to use previous timepoints to predict later values. We can start by using data from the previous year to predict the current year.\n",
    "\n",
    "We're going to multiply the previous value by some number to predict the value for the current year.\n",
    "\n",
    "We can do the same with a lag of 2 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "\n",
    "for i in range(len(y_diff)):\n",
    "    \n",
    "    y_p = \n",
    "    predictions.append(y_p)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "ax.plot(   , label='observed')\n",
    "ax.plot(   , label='pred')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "mean_squared_error \n",
    "\n",
    "print(mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "In groups, using the code in the cell above, try to make a model with the smallest mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a manual version of an **autoregressive (AR) model**. statsmodels has a function `AutoReg` to do the fitting process for us. \n",
    "\n",
    "If we use 1 lag term, we call our model an AR(1) model. If we use 3 lag terms, we call our model an AR(3) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "ax.plot(y_diff, label='observed')\n",
    "ax.plot(y_pred, label='pred')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to model a time series is with a **moving average** model. Instead of using prior values, we use prior error: how much off our predictions were in previous years. \n",
    "\n",
    "To see how many years to look at, we can look at the ACF plot. For our first example, we'll just look at the most recent error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [  ]\n",
    "\n",
    "for i in range(len(y_diff)-1):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "ax.plot( , label='observed')\n",
    "ax.plot( , label='pred')\n",
    "ax.legend();\n",
    "\n",
    "mean_squared_error = np.mean(( - )**2)\n",
    "\n",
    "print(mean_squared_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to AR models, we can use some functions to calculate coefficients for us. The one we will use is called ARIMA (more on this later).\n",
    "\n",
    "In the `order` parameter of the model, we specify how many error terms we will use. If we use 2 error terms, it is an MA(2) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit an MA(2) model to the first simulated data\n",
    "\n",
    "\n",
    "# Print out summary information on the fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "ax.plot(y_diff, label='observed')\n",
    "ax.plot(y_pred, label='pred')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use both AR and MA terms in our model. This is called an ARMA model (we'll get to the I in just a second.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model = ARIMA(y_diff, order=(  )).fit()\n",
    "\n",
    "y_pred \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "ax.plot(y_diff[1:], label='observed')\n",
    "ax.plot(y_pred[1:], label='pred')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Integrated\n",
    "\n",
    "The I in ARIMA stands for integrated. Basically, included a value for I does the differencing for us. This allows us to use our time series without detrending it first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ARIMA( , order=()\n",
    "arima_model = mod.fit()\n",
    "\n",
    "y_pred = arima_model.predict()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "ax.plot(df['temp'][1:], label='observed')\n",
    "ax.plot(y_pred[1:], label='pred')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the correct model is difficult. Next time, we will use a better method for picking the correct ARIMA model, as well as how to forecast, and deal with seasonal data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "In groups, try several different kinds of ARIMA models -> different amounts of AR, I, and MA terms. What combinations lead to the smallest mean squared error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52b534d3e8b2df8a7f375ea8b488ed7c2e546a5d77230d70bd2c6badbd8c861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
